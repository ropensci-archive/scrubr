<!--
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{scrubr introduction}
%\VignetteEncoding{UTF-8}
-->

```{r echo=FALSE}
knitr::opts_chunk$set(
	comment = "#>",
	collapse = TRUE,
	warning = FALSE,
	message = FALSE
)
```

scrubr introduction
===================

`scrubr` is a general purpose toolbox for cleaning biological occurrence records. Think
of it like `dplyr` but specifically for occurrence data. It includes functionality for
cleaning based on various aspects of spatial coordinates, unlikely values due to political
centroids, taxonomic names, and more.

## Installation

Install from CRAN

```{r install, eval=FALSE}
install.packages("scrubr")
```

Or install the development version from GitHub

```{r installgh, eval=FALSE}
devtools::install_github("ropensci/scrubr")
```

Load scrubr

```{r load}
library("scrubr")
```

We'll use sample datasets included with the package, they are lazy loaded,
and available via `sample_data_1` and `sample_data_2`

## data.frame's

All functions expect data.frame's as input, and output data.frame's

## Pipe vs. no pipe

We think that using a piping workflow with `%>%` makes code easier to
build up, and easier to understand. However, in some examples below we provide
commented out examples without the pipe to demonstrate traditional usage - which
you can use if you remove the comment `#` at beginning of the line.

## dframe

`dframe()` is a utility function to create a compact data.frame representation. You 
don't have to use it. If you do, you can work with `scrubr` functions with a compact
data.frame, making it easier to see the data quickly. If you don't use `dframe()`
we just use your regular data.frame. Problem is with large data.frame's you deal with 
lots of stuff printed to the screen, making it hard to quickly wrangle data.

## Coordinate based cleaning

Remove impossible coordinates (using sample data included in the pkg)

```{r}
# coord_impossible(dframe(sample_data_1)) # w/o pipe
dframe(sample_data_1) %>% coord_impossible()
```

Remove incomplete coordinates

```{r}
# coord_incomplete(dframe(sample_data_1)) # w/o pipe
dframe(sample_data_1) %>% coord_incomplete()
```

Remove unlikely coordinates (e.g., those at 0,0)

```{r}
# coord_unlikely(dframe(sample_data_1)) # w/o pipe
dframe(sample_data_1) %>% coord_unlikely()
```

Do all three

```{r}
dframe(sample_data_1) %>%
  coord_impossible() %>%
  coord_incomplete() %>%
  coord_unlikely()
```

Don't drop bad data

```{r}
dframe(sample_data_1) %>% coord_incomplete(drop = TRUE) %>% NROW
dframe(sample_data_1) %>% coord_incomplete(drop = FALSE) %>% NROW
```

## Deduplicate

```{r}
smalldf <- sample_data_1[1:20, ]
# create a duplicate record
smalldf <- rbind(smalldf, smalldf[10,])
row.names(smalldf) <- NULL
# make it slightly different
smalldf[21, "key"] <- 1088954555
NROW(smalldf)
dp <- dframe(smalldf) %>% dedup()
NROW(dp)
attr(dp, "dups")
```

## Dates

Standardize/convert dates

```{r}
# date_standardize(dframe(df), "%d%b%Y") # w/o pipe
dframe(sample_data_1) %>% date_standardize("%d%b%Y")
```

Drop records without dates

```{r}
NROW(sample_data_1)
NROW(dframe(sample_data_1) %>% date_missing())
```

Create date field from other fields

```{r}
dframe(sample_data_2) %>% date_create(year, month, day)
```

## Taxonomy

Only one function exists for taxonomy cleaning, it removes rows where taxonomic names are 
either missing an epithet, or are missing altogether  (`NA` or `NULL`).

Get some data from GBIF, via `rgbif`

```{r}
if (requireNamespace("rgbif", quietly = TRUE)) {
  library("rgbif")
  res <- occ_data(limit = 500)$data
} else {
  res <- sample_data_3
}
```

Clean names

```{r}
NROW(res)
df <- dframe(res) %>% tax_no_epithet(name = "name")
NROW(df)
attr(df, "name_var")
attr(df, "tax_no_epithet")
```
